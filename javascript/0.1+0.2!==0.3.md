```js
function judgeFloat(n, m) {
      const binaryN = n.toString(2);
      const binaryM = m.toString(2);
      console.log(`${n}的二进制是    ${binaryN}`);
      console.log(`${m}的二进制是    ${binaryM}`);
      const MN = m + n;
      const accuracyMN = (m * 100 + n * 100) / 100;
      const binaryMN = MN.toString(2);
      const accuracyBinaryMN = accuracyMN.toString(2);
      console.log(`${n}+${m}的二进制是${binaryMN}`);
      console.log(`${accuracyMN}的二进制是    ${accuracyBinaryMN}`);
      console.log(`${n}+${m}的二进制再转成十进制是${to10(binaryMN)}`);
      console.log(`${accuracyMN}的二进制是再转成十进制是${to10(accuracyBinaryMN)}`);
      console.log(`${n}+${m}在js中计算是${(to10(binaryMN) === to10(accuracyBinaryMN)) ? '' : '不'}准确的`);
    }
    function to10(n) {
      const pre = (n.split('.')[0] - 0).toString(2);
      const arr = n.split('.')[1].split('');
      let i = 0;
      let result = 0;
      while (i < arr.length) {
        result += arr[i] * Math.pow(2, -(i + 1));
        i++;
      }
      return result;
    }
    judgeFloat(0.1, 0.2);
    judgeFloat(0.6, 0.7);
```
![](https://mmbiz.qpic.cn/mmbiz_png/aDoYvepE5x3eYibkd6ffhX7bAU7VMuGzic2QQpNMcqRSUR1tgNBGTVmel2wwGqubxWVMQKDNevfZlx8OuvYIGeyw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
 
## js对二进制小数的存储方式
小数的二进制大多数都是无限循环的
 
在ECMAScript®语言规范中可以看到，ECMAScript中的Number类型遵循IEEE 754标准。使用64位固定长度来表示。

事实上有很多语言的数字类型都遵循这个标准，例如JAVA,所以很多语言同样有着上面同样的问题。

##  IEEE 754
IEEE754标准包含一组实数的二进制表示法。它有三部分组成：

> 符号位

> 指数位

> 尾数位

三种精度的浮点数各个部分位数如下：
![](https://mmbiz.qpic.cn/mmbiz_png/aDoYvepE5x3eYibkd6ffhX7bAU7VMuGzicVHe23FOYGkTFK7hYKqMpQ4ia8KQ4eZlRfkibPxwWBIn8XiaepZ73CicY0g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

JavaScript使用的是64位双精度浮点数编码，所以它的符号位占1位，指数位占11位，尾数位占52位。

以0.1为例：它的二进制为：0.0001100110011001100...

## js中的toString(2)
由于尾数位只能存储52个数字，这就能解释toString(2)的执行结果了：

如果计算机没有存储空间的限制，那么0.1的二进制应该是：

`0.00011001100110011001100110011001100110011001100110011001...`

但是由于限制，有效数字第53位及以后的数字是不能存储的，它遵循，如果是1就向前一位进1，如果是0就舍弃的原则。

0.1的二进制科学计数法第53位是1，所以就有了下面的结果：

`0.0001100110011001100110011001100110011001100110011001101`

0.2有着同样的问题，其实正是由于这样的存储，在这里有了精度丢失，导致了0.1+0.2!=0.3。

以当程序中有数字计算时，我们最好用工具库来帮助我们解决，下面是两个推荐使用的开源库：

`number-precision`

`mathjs`
